{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bug Check Report\n",
    "\n",
    "## 1. Introduction\n",
    "The purpose of this notebok is to thoroughly go through and test the two simulators to determine why the new simulator is not producing the expected behaviour in the new environments. There are a few possibilities:\n",
    "\n",
    "1. The old simulator had a bug or mistake in it;\n",
    "2. The new simulator has a bug or mistake in it;\n",
    "3. The new simulator has a bug or mistake in it;\n",
    "4. The old simulator has a bug or mistake in it.\n",
    "\n",
    "We can test these by comparing the old simulator with the new simulator to determine if the physics are the same. If they are, then it's reasonable to conclude that the problem is in the environment. However, we should also test whether or noth the aerodynamic effects included in the old simulator are also partly responsible for the behavior. We can do this  by testing the old and new simulators in the new environment wrapper and seeing if the behavior is as expected (this is easier than trying to test the old environments with the new simulator, which we should only do if we can't find any other alternative).\n",
    "\n",
    "## 2. Comparing Simulations\n",
    "\n",
    "Tests:\n",
    "\n",
    "1. Gravity test -- we initialize from hover rpm, and then command it to zero. We let the aircraft fall for 1 second, and output the velocity and position. These should be roughly 9.81m/s in the z-direction, and ...\n",
    "2. Climb test -- we initialize the aircraft to hover rpm, and then provide an input command of maximum rpm. We know that the aircraft should accelerate at 1g (since we've selected values this way), which means that the final velocity should be ~9.81m/s in the upwards direction, and ...;\n",
    "3. Hover test -- we initialize the aircraft to hover rpm, and then provide an input command of hover rpm. The aircraft should remain static;\n",
    "4. Roll test -- we initialize the aircraft to hover rpm, and then provide an input command of maximum rpm at one of the motors. We then measure the output values after 1 second; and,\n",
    "5. Motor response -- we conduct one of the previous tests, except this time, we output the motor response. If we use the same values, we expect that they should be roughly the same.\n",
    "\n",
    "If these tests don't throw anything up, the next step is to check the environment using both simulations. This will tell us if there's something wrong with the simulation or environment.\n",
    "\n",
    "### 2.1 Old Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quadrotor3 as quad\n",
    "import animation as ani\n",
    "import config as cfg\n",
    "import numpy as np\n",
    "\n",
    "gravity_arr = []\n",
    "climb_arr = []\n",
    "hover_arr = []\n",
    "roll_arr = []\n",
    "\n",
    "params = cfg.params\n",
    "iris = quad.Quadrotor(params)\n",
    "T = 0.5\n",
    "sim_dt = iris.dt\n",
    "ctrl_dt = 0.01\n",
    "time = np.linspace(0, T, T/ctrl_dt)\n",
    "\n",
    "## Start the tests ##\n",
    "\n",
    "print(\"Testing Gravity\")\n",
    "counter = 0\n",
    "frames = 5\n",
    "rpm = np.array([0., 0., 0., 0.])\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz, zeta, uvw, pqr = iris.reset()\n",
    "xyz_arr.append(xyz.reshape((3,)))\n",
    "zeta_arr.append(zeta.reshape((3,))) \n",
    "uvw_arr.append(uvw.reshape((3,)))\n",
    "pqr_arr.append(pqr.reshape((3,))) \n",
    "rpm_arr.append(iris.get_rpm())\n",
    "for t in time:\n",
    "    xyz, zeta, uvw, pqr = iris.step(rpm)\n",
    "    xyz_arr.append(xyz.reshape((3,)))\n",
    "    zeta_arr.append(zeta.reshape((3,))) \n",
    "    uvw_arr.append(uvw.reshape((3,)))\n",
    "    pqr_arr.append(pqr.reshape((3,))) \n",
    "    rpm_arr.append(iris.get_rpm())\n",
    "print(\"Time: \", t)\n",
    "print(\"xyz: \", xyz.reshape((3,)))\n",
    "print(\"zeta: \", zeta.reshape((3,)))\n",
    "print(\"uvw: \", uvw.reshape((3,)))\n",
    "print(\"pqr: \", pqr.reshape((3,)))\n",
    "gravity_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "\n",
    "print(\"Testing Climb\")\n",
    "counter = 0\n",
    "frames = 5\n",
    "max_rpm = iris.max_rpm\n",
    "rpm = np.array([max_rpm, max_rpm, max_rpm, max_rpm])\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz, zeta, uvw, pqr = iris.reset()\n",
    "xyz_arr.append(xyz.reshape((3,)))\n",
    "zeta_arr.append(zeta.reshape((3,))) \n",
    "uvw_arr.append(uvw.reshape((3,)))\n",
    "pqr_arr.append(pqr.reshape((3,))) \n",
    "rpm_arr.append(iris.get_rpm())\n",
    "for t in time:\n",
    "    xyz, zeta, uvw, pqr = iris.step(rpm)\n",
    "    xyz, zeta, uvw, pqr = iris.reset()\n",
    "    xyz_arr.append(xyz.reshape((3,)))\n",
    "    zeta_arr.append(zeta.reshape((3,))) \n",
    "    uvw_arr.append(uvw.reshape((3,)))\n",
    "    pqr_arr.append(pqr.reshape((3,))) \n",
    "    rpm_arr.append(iris.get_rpm())\n",
    "print(\"Time: \", t)\n",
    "print(\"xyz: \", xyz.reshape((3,)))\n",
    "print(\"zeta: \", zeta.reshape((3,)))\n",
    "print(\"uvw: \", uvw.reshape((3,)))\n",
    "print(\"pqr: \", pqr.reshape((3,)))\n",
    "climb_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "\n",
    "print(\"Testing Hover\")\n",
    "counter = 0\n",
    "frames = 5\n",
    "hover_rpm = iris.hov_rpm\n",
    "rpm = np.array([hover_rpm, hover_rpm, hover_rpm, hover_rpm])\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz, zeta, uvw, pqr = iris.reset()\n",
    "xyz_arr.append(xyz.reshape((3,)))\n",
    "zeta_arr.append(zeta.reshape((3,))) \n",
    "uvw_arr.append(uvw.reshape((3,)))\n",
    "pqr_arr.append(pqr.reshape((3,))) \n",
    "rpm_arr.append(iris.get_rpm())\n",
    "for t in time:\n",
    "    xyz, zeta, uvw, pqr = iris.step(rpm)\n",
    "    xyz, zeta, uvw, pqr = iris.reset()\n",
    "    xyz_arr.append(xyz.reshape((3,)))\n",
    "    zeta_arr.append(zeta.reshape((3,))) \n",
    "    uvw_arr.append(uvw.reshape((3,)))\n",
    "    pqr_arr.append(pqr.reshape((3,))) \n",
    "    rpm_arr.append(iris.get_rpm())\n",
    "print(\"Time: \", t)\n",
    "print(\"xyz: \", xyz.reshape((3,)))\n",
    "print(\"zeta: \", zeta.reshape((3,)))\n",
    "print(\"uvw: \", uvw.reshape((3,)))\n",
    "print(\"pqr: \", pqr.reshape((3,)))\n",
    "hover_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "\n",
    "print(\"Testing Roll\")\n",
    "counter = 0\n",
    "frames = 5\n",
    "rpm = np.array([hover_rpm, hover_rpm, hover_rpm, hover_rpm])\n",
    "rpm += np.array([0., 0., 0., 5.])\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz, zeta, uvw, pqr = iris.reset()\n",
    "xyz_arr.append(xyz.reshape((3,)))\n",
    "zeta_arr.append(zeta.reshape((3,))) \n",
    "uvw_arr.append(uvw.reshape((3,)))\n",
    "pqr_arr.append(pqr.reshape((3,))) \n",
    "rpm_arr.append(iris.get_rpm())\n",
    "for t in time:\n",
    "    xyz, zeta, uvw, pqr = iris.step(rpm)\n",
    "    xyz, zeta, uvw, pqr = iris.reset()\n",
    "    xyz_arr.append(xyz.reshape((3,)))\n",
    "    zeta_arr.append(zeta.reshape((3,))) \n",
    "    uvw_arr.append(uvw.reshape((3,)))\n",
    "    pqr_arr.append(pqr.reshape((3,))) \n",
    "    rpm_arr.append(iris.get_rpm())\n",
    "print(\"Time: \", t)\n",
    "print(\"xyz: \", xyz.reshape((3,)))\n",
    "print(\"zeta: \", zeta.reshape((3,)))\n",
    "print(\"uvw: \", uvw.reshape((3,)))\n",
    "print(\"pqr: \", pqr.reshape((3,)))\n",
    "roll_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we'll run tests on the new simulator:\n",
    "\n",
    "### 2.2 New Simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ctypes\n",
    "\n",
    "import random\n",
    "from math import pi, sin, cos, tanh, exp, sqrt, acos\n",
    "\n",
    "import time\n",
    "\n",
    "class Quadrotor:\n",
    "    def __init__(self):\n",
    "        self.iris = ctypes.CDLL(\"/home/seanny/gym-aero/simulation/quadrotor_sim.so\")\n",
    "        self.iris.sim_step.argtypes = [ctypes.c_double, ctypes.c_double, ctypes.c_double, ctypes.c_double]\n",
    "        self.iris.set_init_pos.argtypes = [ctypes.c_double, ctypes.c_double, ctypes.c_double]\n",
    "        self.iris.set_init_euler.argtypes = [ctypes.c_double, ctypes.c_double, ctypes.c_double]\n",
    "        self.iris.set_init_vel.argtypes = [ctypes.c_double, ctypes.c_double, ctypes.c_double]\n",
    "        self.iris.set_init_omega.argtypes = [ctypes.c_double, ctypes.c_double, ctypes.c_double]\n",
    "        self.iris.set_init_rpm.argtypes = [ctypes.c_double, ctypes.c_double, ctypes.c_double, ctypes.c_double]\n",
    "        self.iris.set_min_rpm.argtypes = [ctypes.c_double]\n",
    "        self.iris.set_max_rpm.argtypes = [ctypes.c_double]\n",
    "\n",
    "        self.iris.get_x.restype = ctypes.c_double\n",
    "        self.iris.get_y.restype = ctypes.c_double\n",
    "        self.iris.get_z.restype = ctypes.c_double\n",
    "\n",
    "        self.iris.get_phi.restype = ctypes.c_double\n",
    "        self.iris.get_theta.restype = ctypes.c_double\n",
    "        self.iris.get_psi.restype = ctypes.c_double\n",
    "\n",
    "        self.iris.get_u.restype = ctypes.c_double\n",
    "        self.iris.get_v.restype = ctypes.c_double\n",
    "        self.iris.get_w.restype = ctypes.c_double\n",
    "\n",
    "        self.iris.get_p.restype = ctypes.c_double\n",
    "        self.iris.get_q.restype = ctypes.c_double\n",
    "        self.iris.get_r.restype = ctypes.c_double\n",
    "\n",
    "        #self.iris.get_time_step.restype = ctypes.c_float\n",
    "        self.iris.get_mass.restype = ctypes.c_float\n",
    "        self.iris.get_gravity.restype = ctypes.c_float\n",
    "        self.iris.get_torque_coeff.restype = ctypes.c_float\n",
    "        self.iris.get_thrust_coeff.restype = ctypes.c_float\n",
    "\n",
    "        self.iris.get_rpm_0.restype = ctypes.c_float\n",
    "        self.iris.get_rpm_1.restype = ctypes.c_float\n",
    "        self.iris.get_rpm_2.restype = ctypes.c_float\n",
    "        self.iris.get_rpm_3.restype = ctypes.c_float\n",
    "\n",
    "        self.init_rendering = False\n",
    "\n",
    "        self.ac_mass = self.iris.get_mass()\n",
    "        self.sim_gravity = self.iris.get_gravity()\n",
    "        self.torque_coeff = self.iris.get_torque_coeff()\n",
    "        self.thrust_coeff = self.iris.get_thrust_coeff()\n",
    "\n",
    "        self.T = 0.5\n",
    "        self.t = 0\n",
    "        self.dt = 0.01 #self.iris.get_time_step()\n",
    "        self.ctrl_dt = 0.01\n",
    "        self.max_rpm = self.omega_to_rpm(sqrt(self.ac_mass*self.sim_gravity/(2.*self.thrust_coeff)))\n",
    "        self.hov_rpm = self.omega_to_rpm(sqrt(self.ac_mass*self.sim_gravity/(4.*self.thrust_coeff)))\n",
    "        self.hov_rpm_ = [self.hov_rpm, self.hov_rpm, self.hov_rpm, self.hov_rpm]\n",
    "        self.hov_omega = self.hov_rpm*pi/30.\n",
    "        self.action_bandwidth = 35.\n",
    "\n",
    "        print(\"Simulation parameters:\")\n",
    "        print(\"Aircraft mass: \", self.ac_mass)\n",
    "        print(\"Gravity: \", self.sim_gravity)\n",
    "        print(\"Torque coefficient: \", self.torque_coeff)\n",
    "        print(\"Thrust coefficient: \", self.thrust_coeff)\n",
    "        print(\"Maximum RPM: \", self.max_rpm)\n",
    "        print(\"Hover RPM: \", self.hov_rpm)\n",
    "        print(\"Hover Omega: \", self.hov_omega)\n",
    "        \n",
    "    def get_data(self):\n",
    "        x = self.iris.get_x()\n",
    "        y = self.iris.get_y()\n",
    "        z = self.iris.get_z()\n",
    "\n",
    "        phi = self.iris.get_phi()\n",
    "        theta = self.iris.get_theta()\n",
    "        psi = self.iris.get_psi()\n",
    "\n",
    "        u = self.iris.get_u()\n",
    "        v = self.iris.get_v()\n",
    "        w = self.iris.get_w()\n",
    "\n",
    "        p = self.iris.get_p()\n",
    "        q = self.iris.get_q()\n",
    "        r = self.iris.get_r()\n",
    "        return [x, y, z], [phi, theta, psi], [u, v, w], [p, q, r]\n",
    "\n",
    "    def get_rpm(self):\n",
    "        m_0 = self.iris.get_rpm_0()\n",
    "        m_1 = self.iris.get_rpm_1()\n",
    "        m_2 = self.iris.get_rpm_2()\n",
    "        m_3 = self.iris.get_rpm_3()\n",
    "        return [m_0, m_1, m_2, m_3]\n",
    "\n",
    "    def omega_to_rpm(self, omega):\n",
    "        return omega*30./pi\n",
    "    \n",
    "    def rpm_to_omega(self, rpm):\n",
    "        return rpm*pi/30.\n",
    "\n",
    "\n",
    "## Start the tests ##\n",
    "    \n",
    "quad = Quadrotor()\n",
    "n = int(quad.ctrl_dt/quad.dt)\n",
    "print(\"Number of timesteps per action: \", n)\n",
    "sim_steps = int(quad.T/quad.ctrl_dt)\n",
    "\n",
    "print(\"Testing Gravity\")\n",
    "quad.iris.set_init_rpm(quad.hov_rpm, quad.hov_rpm, quad.hov_rpm, quad.hov_rpm)\n",
    "quad.iris.sim_init()\n",
    "quad.iris.set_max_rpm(quad.max_rpm)\n",
    "print(\"Init RPM: \", quad.get_rpm())\n",
    "print(quad.hov_rpm)\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz_arr.append(np.array(xyz))\n",
    "zeta_arr.append(np.array(zeta)) \n",
    "uvw_arr.append(np.array(uvw))\n",
    "pqr_arr.append(np.array(pqr))\n",
    "rpm_arr.append(np.array(iris.get_rpm()))\n",
    "for i in range(sim_steps):\n",
    "    quad.iris.sim_step(0., 0., 0., 0., n)\n",
    "    xyz, zeta, uvw, pqr = quad.get_data()\n",
    "    xyz_arr.append(np.array(xyz))\n",
    "    zeta_arr.append(np.array(zeta)) \n",
    "    uvw_arr.append(np.array(uvw))\n",
    "    pqr_arr.append(np.array(pqr))\n",
    "    rpm_arr.append(np.array(iris.get_rpm()))\n",
    "    quad.t += quad.ctrl_dt\n",
    "print(\"Time: \", quad.t)\n",
    "print(\"xyz: \", xyz)\n",
    "print(\"zeta: \", zeta)\n",
    "print(\"uvw: \", uvw)\n",
    "print(\"pqr: \", pqr)\n",
    "print()\n",
    "gravity_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "quad.iris.sim_term()\n",
    "\n",
    "print(\"Testing Climb Rate\")\n",
    "quad.iris.set_init_rpm(quad.hov_rpm, quad.hov_rpm, quad.hov_rpm, quad.hov_rpm)\n",
    "quad.iris.sim_init()\n",
    "quad.iris.set_max_rpm(quad.max_rpm)\n",
    "print(\"Init RPM: \", quad.get_rpm())\n",
    "print(quad.hov_rpm)\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz_arr.append(np.array(xyz))\n",
    "zeta_arr.append(np.array(zeta)) \n",
    "uvw_arr.append(np.array(uvw))\n",
    "pqr_arr.append(np.array(pqr))\n",
    "rpm_arr.append(np.array(iris.get_rpm()))\n",
    "for i in range(sim_steps):\n",
    "    quad.iris.sim_step(quad.max_rpm, quad.max_rpm, quad.max_rpm, quad.max_rpm, n)\n",
    "    xyz_arr.append(np.array(xyz))\n",
    "    zeta_arr.append(np.array(zeta)) \n",
    "    uvw_arr.append(np.array(uvw))\n",
    "    pqr_arr.append(np.array(pqr))\n",
    "    rpm_arr.append(np.array(iris.get_rpm()))\n",
    "    quad.t += quad.ctrl_dt\n",
    "print(\"Time: \", quad.t)\n",
    "print(\"xyz: \", xyz)\n",
    "print(\"zeta: \", zeta)\n",
    "print(\"uvw: \", uvw)\n",
    "print(\"pqr: \", pqr)\n",
    "print()\n",
    "climb_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "quad.iris.sim_term()\n",
    "\n",
    "print(\"Testing Hover\")\n",
    "quad.iris.set_init_rpm(quad.max_rpm, quad.max_rpm, quad.max_rpm, quad.max_rpm)\n",
    "quad.iris.sim_init()\n",
    "quad.iris.set_max_rpm(quad.max_rpm)\n",
    "print(\"Init RPM: \", quad.get_rpm())\n",
    "print(quad.hov_rpm)\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz_arr.append(np.array(xyz))\n",
    "zeta_arr.append(np.array(zeta)) \n",
    "uvw_arr.append(np.array(uvw))\n",
    "pqr_arr.append(np.array(pqr))\n",
    "rpm_arr.append(np.array(iris.get_rpm()))\n",
    "for i in range(sim_steps):\n",
    "    quad.iris.sim_step(quad.hov_rpm, quad.hov_rpm, quad.hov_rpm, quad.hov_rpm, n)\n",
    "    xyz_arr.append(np.array(xyz))\n",
    "    zeta_arr.append(np.array(zeta)) \n",
    "    uvw_arr.append(np.array(uvw))\n",
    "    pqr_arr.append(np.array(pqr))\n",
    "    rpm_arr.append(np.array(iris.get_rpm()))\n",
    "    quad.t += quad.ctrl_dt\n",
    "print(\"Time: \", quad.t)\n",
    "print(\"xyz: \", xyz)\n",
    "print(\"zeta: \", zeta)\n",
    "print(\"uvw: \", uvw)\n",
    "print(\"pqr: \", pqr)\n",
    "print()\n",
    "hover_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "quad.iris.sim_term()\n",
    "\n",
    "print(\"Testing Roll\")\n",
    "k = 5*(30/pi)\n",
    "quad.iris.set_init_rpm(quad.hov_rpm, quad.hov_rpm, quad.hov_rpm, quad.hov_rpm)\n",
    "quad.iris.sim_init()\n",
    "quad.iris.set_max_rpm(quad.max_rpm)\n",
    "print(\"Init RPM: \", quad.get_rpm())\n",
    "print(quad.hov_rpm)\n",
    "xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr = [], [], [], [], []\n",
    "xyz_arr.append(np.array(xyz))\n",
    "zeta_arr.append(np.array(zeta)) \n",
    "uvw_arr.append(np.array(uvw))\n",
    "pqr_arr.append(np.array(pqr))\n",
    "rpm_arr.append(np.array(iris.get_rpm()))\n",
    "for i in range(sim_steps):\n",
    "    quad.iris.sim_step(quad.hov_rpm, quad.hov_rpm, quad.hov_rpm, quad.hov_rpm+5*k, n)\n",
    "    xyz_arr.append(np.array(xyz))\n",
    "    zeta_arr.append(np.array(zeta)) \n",
    "    uvw_arr.append(np.array(uvw))\n",
    "    pqr_arr.append(np.array(pqr))\n",
    "    rpm_arr.append(np.array(iris.get_rpm()))\n",
    "    quad.t += quad.ctrl_dt\n",
    "print(\"Time: \", quad.t)\n",
    "print(\"xyz: \", xyz)\n",
    "print(\"zeta: \", zeta)\n",
    "print(\"uvw: \", uvw)\n",
    "print(\"pqr: \", pqr)\n",
    "print()\n",
    "roll_arr.append([xyz_arr, zeta_arr, uvw_arr, pqr_arr, rpm_arr])\n",
    "quad.iris.sim_term()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Plotting Results\n",
    "\n",
    "#### 2.3.1 Plot Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%matplotlib inline\n",
    "clear_output(True)\n",
    "\n",
    "def plot_figures(dataset):\n",
    "    fig, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12)) = plt.subplots(4, 3, figsize=(12,12))\n",
    "    fig.suptitle(\"Gravity Test\", fontsize=14)\n",
    "\n",
    "    ax1.set_title(\"Inertial X-Position\")\n",
    "    ax1.set_xlabel(\"Time (s)\")\n",
    "    ax1.set_ylabel(\"Position (m)\")\n",
    "\n",
    "    ax2.set_title(\"Inertial Y-Position\")\n",
    "    ax2.set_xlabel(\"Time (s)\")\n",
    "    ax2.set_ylabel(\"Position (m)\")\n",
    "\n",
    "    ax3.set_title(\"Inertial Z-Position\")\n",
    "    ax3.set_xlabel(\"Time (s)\")\n",
    "    ax3.set_ylabel(\"Position (m)\")\n",
    "\n",
    "    ax4.set_title(\"Roll Angle\")\n",
    "    ax4.set_xlabel(\"Time (s)\")\n",
    "    ax4.set_ylabel(\"Angle (rad)\")\n",
    "\n",
    "    ax5.set_title(\"Pitch Angle\")\n",
    "    ax5.set_xlabel(\"Time (s)\")\n",
    "    ax5.set_ylabel(\"Angle (rad)\")\n",
    "\n",
    "    ax6.set_title(\"Yaw Angle\")\n",
    "    ax6.set_xlabel(\"Time (s)\")\n",
    "    ax6.set_ylabel(\"Angle (rad)\")\n",
    "\n",
    "    ax7.set_title(\"Body U-Velocity\")\n",
    "    ax7.set_xlabel(\"Time (s)\")\n",
    "    ax7.set_ylabel(\"Velocity (m/s)\")\n",
    "\n",
    "    ax8.set_title(\"Body V-Velocity\")\n",
    "    ax8.set_xlabel(\"Time (s)\")\n",
    "    ax8.set_ylabel(\"Velocity (m/s)\")\n",
    "\n",
    "    ax9.set_title(\"Body W-Velocity\")\n",
    "    ax9.set_xlabel(\"Time (s)\")\n",
    "    ax9.set_ylabel(\"Velocity (m/s)\")\n",
    "\n",
    "    ax10.set_title(\"Body P-Velocity\")\n",
    "    ax10.set_xlabel(\"Time (s)\")\n",
    "    ax10.set_ylabel(\"Angular Velocity (rad/s)\")\n",
    "\n",
    "    ax11.set_title(\"Body Q-Velocity\")\n",
    "    ax11.set_xlabel(\"Time (s)\")\n",
    "    ax11.set_ylabel(\"Angular Velocity (rad/s)\")\n",
    "\n",
    "    ax12.set_title(\"Body R-Velocity\")\n",
    "    ax12.set_xlabel(\"Time (s)\")\n",
    "    ax12.set_ylabel(\"Angular Velocity (m/s)\")\n",
    "\n",
    "    ## RPM response\n",
    "\n",
    "    fig2, (ax13, ax14, ax15, ax16) = plt.subplots(1, 4, figsize=(12,12))\n",
    "    fig2.suptitle(\"Motor Responses\", fontsize=14)\n",
    "\n",
    "    ax13.set_title(\"Motor 1\")\n",
    "    ax13.set_xlabel(\"Time (s)\")\n",
    "    ax13.set_ylabel(\"RPM\")\n",
    "\n",
    "    ax14.set_title(\"Motor 2\")\n",
    "    ax14.set_xlabel(\"Time (s)\")\n",
    "    ax14.set_ylabel(\"RPM\")\n",
    "\n",
    "    ax15.set_title(\"Motor 3\")\n",
    "    ax15.set_xlabel(\"Time (s)\")\n",
    "    ax15.set_ylabel(\"RPM\")\n",
    "\n",
    "    ax16.set_title(\"Motor 4\")\n",
    "    ax16.set_xlabel(\"Time (s)\")\n",
    "    ax16.set_ylabel(\"RPM\")\n",
    "\n",
    "    for d in dataset:\n",
    "        t, xyz, zeta, uvw, pqr, rpm = d\n",
    "        ax1.plot(t, xyz[0])\n",
    "        ax2.plot(t, xyz[1])\n",
    "        ax3.plot(t, xyz[2])\n",
    "\n",
    "        ax4.plot(t, zeta[0])\n",
    "        ax5.plot(t, zeta[1])\n",
    "        ax6.plot(t, zeta[2])\n",
    "\n",
    "        ax7.plot(t, uvw[0])\n",
    "        ax8.plot(t, uvw[1])\n",
    "        ax9.plot(t, uvw[2])\n",
    "\n",
    "        ax10.plot(t, pqr[0])\n",
    "        ax11.plot(t, pqr[1])\n",
    "        ax12.plot(t, pqr[2])\n",
    "\n",
    "        ax13.plot(t, rpm[0])\n",
    "        ax14.plot(t, rpm[1])\n",
    "        ax15.plot(t, rpm[2])\n",
    "        ax16.plot(t, rpm[3])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Gravity Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures(gravity_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Climb Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures(climb_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.4 Hover Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures(hover_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.5 Roll Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figures(roll_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Testing the old simulator in the new environment wrappers\n",
    "This is a fair bit easier than using the new simulator in the old environment wrappers, since we only need to change the output of the sim to a list. In this case, we will do two tests:\n",
    "\n",
    "1. We use the new simulator in the new environment wrappers as a baseline to test against.\n",
    "2. We use the old simulator in the new environment wrappers with no aerodynamic forces or moments to determine if the behavior is the same.\n",
    "3. We use the old simulator in the new environment wrappers with aerodynamic forces and moments to determine if this is having an effect.\n",
    "\n",
    "Depending on the outcome of these experiments, we should know if the environment or simulator is at fault.\n",
    "\n",
    "First off, we inherit the standard environment class, and then change simulation. This will tell us if the environment or the simulation is responsible:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import gym_aero\n",
    "import gym_aero.envs.trajectory_env as trajectory_env\n",
    "import quadrotor3 as quad\n",
    "import animation as ani\n",
    "import config as cfg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "\n",
    "from math import sin, cos, pi\n",
    "\n",
    "class TrajectoryEnvCompare(trajectory_env.TrajectoryEnv):\n",
    "    def __init__(self):\n",
    "        super(TrajectoryEnvCompare, self).__init__()\n",
    "        self.iris = quad3.Quadrotor()\n",
    "        \n",
    "    def translate_action(self, action):\n",
    "        return (np.array(self.hov_rpm_)+self.bandwidth*action)*pi/30\n",
    "\n",
    "    def translate_state(self, state):\n",
    "        xyz, zeta, uvw, pqr = state\n",
    "        return xyz[:,0].tolist(), zeta[:,0].tolist(), uvw[:,0].tolist(), pqr[:,0].tolist()\n",
    "    \n",
    "    def step(self, action):\n",
    "        # translate action output of controller to simulation rpm\n",
    "        commanded_omega = self.translate_action(action)\n",
    "\n",
    "        # step simulation forward\n",
    "        xyz, zeta, uvw, pqr = self.iris.step(commanded_omega)\n",
    "        xyz, zeta, uvw, pqr = self.translate_state((xyz, zeta, uvw, pqr))\n",
    "        \n",
    "        # calculate state representation values\n",
    "        sin_zeta = [sin(z) for z in zeta]\n",
    "        cos_zeta = [cos(z) for z in zeta]\n",
    "        current_rpm = self.iris.get_rpm()\n",
    "        normalized_rpm = [rpm/self.max_rpm for rpm in current_rpm]\n",
    "\n",
    "        # calculate current distances from goals\n",
    "        self.set_current_dists((xyz, sin_zeta, cos_zeta, uvw, pqr), commanded_rpm, normalized_rpm)\n",
    "\n",
    "        # calculate reward based on distances\n",
    "        reward, info = self.reward((xyz, sin_zeta, cos_zeta, uvw, pqr), commanded_rpm, normalized_rpm)\n",
    "        \n",
    "        # if agent is within goal threshold, switch to next goal\n",
    "        if self.curr_dist <= self.goal_thresh: self.next_goal()\n",
    "        \n",
    "        # check if terminal\n",
    "        done = self.terminal()\n",
    "\n",
    "        # get state observation\n",
    "        obs = self.get_state_obs((xyz, sin_zeta, cos_zeta, uvw, pqr), commanded_rpm, normalized_rpm)\n",
    "        \n",
    "        # set previous distances\n",
    "        self.set_prev_dists((xyz, sin_zeta, cos_zeta, uvw, pqr), commanded_rpm, normalized_rpm)\n",
    "        \n",
    "        # increment time\n",
    "        self.t += 1\n",
    "        return obs, reward, done, info\n",
    "    \n",
    "    def reset(self):\n",
    "        # terminate previous sim, initialize new one\n",
    "        xyz, sin_zeta, cos_zeta, uvw, pqr, normalized_rpm = super(TrajectoryEnv, self).reset()\n",
    "        \n",
    "        # generate waypoint positions\n",
    "        self.goal_list_xyz = []\n",
    "        xyz_temp = [0., 0., 0.]\n",
    "        for _ in range(self.traj_len):\n",
    "            goal = self.generate_waypoint()\n",
    "            temp = [x + g for x,g in zip(xyz_temp, goal)]\n",
    "            self.goal_list_xyz.append(temp)\n",
    "            xyz_temp = temp\n",
    "        \n",
    "        # generate goal angles\n",
    "        self.goal_list_zeta = []\n",
    "        i = self.traj_len-2\n",
    "        while True:\n",
    "            temp = self.goal_list_xyz[i+1]\n",
    "            xyz = [0., 0., 0.] if i < 0 else self.goal_list_xyz[i]\n",
    "            yaw = self.generate_yaw(temp, xyz)\n",
    "            self.goal_list_zeta.append(yaw)\n",
    "            if i < 0: break\n",
    "            i -= 1\n",
    "        \n",
    "        # set current goal, next goal\n",
    "        self.goal = 0\n",
    "        self.goal_next = self.goal+1\n",
    "        self.goal_xyz = self.goal_list_xyz[self.goal]\n",
    "        self.goal_xyz_next = self.goal_list_xyz[self.goal_next]\n",
    "        self.goal_zeta = self.goal_list_zeta[self.goal]\n",
    "        self.goal_zeta_next = self.goal_list_zeta[self.goal_next]\n",
    "        \n",
    "        # calculate current distance to goals\n",
    "        self.set_current_dists((xyz, sin_zeta, cos_zeta, uvw, pqr), self.hov_rpm_, normalized_rpm)\n",
    "        \n",
    "        # get state observation\n",
    "        obs = self.get_state_obs((xyz, sin_zeta, cos_zeta, uvw, pqr), self.hov_rpm_, normalized_rpm)\n",
    "        \n",
    "        # set previous distances\n",
    "        self.set_prev_dists((xyz, sin_zeta, cos_zeta, uvw, pqr), self.hov_rpm_, normalized_rpm)\n",
    "        return obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement basic training loops for Monte Carlo Policy Gradients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def plot(episodes, rewards):\n",
    "    clear_output(True)\n",
    "    plt.figure(figsize=(20,5))\n",
    "    plt.subplot(131)\n",
    "    plt.title(\"frame %s. reward: %s\" % (episodes[-1], rewards[-1]))\n",
    "    plt.plot(episodes, rewards)\n",
    "    plt.show()\n",
    "    \n",
    "def test_agent(env, agent):\n",
    "    state = torch.Tensor(env.reset()).to(device)\n",
    "    reward_sum = 0.\n",
    "    done = False\n",
    "    while not done:\n",
    "        action, value, log_prob = agent.select_action(state)\n",
    "        next_state, reward, done, info = env.step(action.cpu().data.numpy())\n",
    "        reward_sum += reward\n",
    "        next_state = torch.Tensor(next_state).to(device)\n",
    "        state = next_state\n",
    "    return reward_sum\n",
    "    \n",
    "def rollout(env, agent, batch_size=2048, render=False):\n",
    "    s_, a_, ns_, r_, lp_, t_lp_, masks, g_ = [], [], [], [], [], [], [], []\n",
    "    num_steps = 0\n",
    "    while num_steps < batch_size:\n",
    "        state = torch.Tensor(env.reset()).to(device)\n",
    "        t = 0\n",
    "        done = False\n",
    "        while not done:\n",
    "            if render: env.render()\n",
    "            action, value, log_prob = agent.select_action(state)\n",
    "            next_state, reward, done, info = env.step(action.cpu().data.numpy())\n",
    "            \n",
    "            next_state = torch.Tensor(next_state).to(device) \n",
    "            reward = torch.Tensor([reward]).to(device)\n",
    "            \n",
    "            s_.append(state)\n",
    "            ns_.append(next_state)\n",
    "            a_.append(action)\n",
    "            r_.append(reward)\n",
    "            lp_.append(log_prob)\n",
    "            masks.append(torch.Tensor([not done]).to(device))\n",
    "            \n",
    "            g_.append(env.goal_xyz)    \n",
    "            state = next_state\n",
    "            t += 1\n",
    "        num_steps += t\n",
    "    if render: env.render(close=True)\n",
    "    trajectory = {\n",
    "                \"states\": s_,\n",
    "                \"actions\": a_,\n",
    "                \"rewards\": r_,\n",
    "                \"next_states\": ns_,\n",
    "                \"masks\": masks,\n",
    "                \"log_probs\": lp_,\n",
    "                \"goals\":g_\n",
    "                }\n",
    "    return trajectory\n",
    "    \n",
    "def train_standard(env, agent, crit_opt, iterations=1000, batch_size=2048, log_interval=10, render=False, fname=None):\n",
    "    rews = []\n",
    "    eps = []\n",
    "    for ep in range(1, iterations+1):\n",
    "        trajectory = rollout(env, agent, batch_size, render=render)\n",
    "        agent.update(crit_opt, trajectory)\n",
    "        if ep % log_interval == 0:\n",
    "            eps.append(ep)\n",
    "            test_rew = np.mean([test_agent(env, agent) for _ in range(10)])\n",
    "            rews.append(test_rew) \n",
    "            plot(eps, rews)\n",
    "    if fname is not None: torch.save(agent.state_dict(), fname+\"_standard.pth.tar\")\n",
    "    env.render(close=True)\n",
    "    return eps, rews, agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement standard reward function for the two agents. We will use the same algorithms, with the same reward function in the same environment, but with the different simulators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sin, cos\n",
    "\n",
    "def reward_func(self, state, action, normalized_rpm):\n",
    "        xyz, sin_zeta, cos_zeta, uvw, pqr = state\n",
    "\n",
    "        # agent gets a negative reward based on how far away it is from the desired goal state\n",
    "        dist_rew = 100*(self.prev_dist-self.curr_dist)\n",
    "        att_rew = 100*(self.prev_att_sin+self.prev_att_cos-self.curr_att_sin-self.curr_att_cos)\n",
    "        vel_rew = 50*(self.prev_vel-self.curr_vel)\n",
    "        ang_rew = 50*(self.prev_ang-self.curr_ang)\n",
    "\n",
    "        # agent gets a negative reward for excessive action inputs\n",
    "        ctrl_rew = -sum([((a-self.hov_rpm)/self.max_rpm)**2 for a in action])\n",
    "        ctrl_rew -= sum([((a-pa)/self.max_rpm)**2 for a, pa in zip(action, self.prev_action)])\n",
    "        ctrl_rew -= 0*sum([(x-y)**2 for x, y in zip(xyz, self.prev_xyz)])\n",
    "        ctrl_rew -= 0*sum([(z-sin(k))**2 for z, k in zip(sin_zeta, self.prev_zeta)])\n",
    "        ctrl_rew -= 0*sum([(z-cos(k))**2 for z, k in zip(cos_zeta, self.prev_zeta)])\n",
    "        ctrl_rew -= 10*sum([(u-v)**2 for u, v in zip(uvw, self.prev_uvw)])\n",
    "        ctrl_rew -= 10*sum([(p-q)**2 for p, q in zip(pqr, self.prev_pqr)])\n",
    "\n",
    "        # time reward for staying in the air\n",
    "        time_rew = 0\n",
    "\n",
    "        # calculate total reward\n",
    "        total_reward = dist_rew+att_rew+vel_rew+ang_rew+ctrl_rew+time_rew\n",
    "        return total_reward, {\"dist_rew\": dist_rew, \n",
    "                                \"att_rew\": att_rew, \n",
    "                                \"vel_rew\": vel_rew,\n",
    "                                \"ang_rew\": ang_rew,\n",
    "                                \"ctrl_rew\": ctrl_rew,\n",
    "                                \"time_rew\": time_rew}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "env_one = gym.make(\"Trajectory-v0\")\n",
    "env_one.goal_thresh = 0.1\n",
    "env_one.reward = MethodType(reward_func, env_one)\n",
    "\n",
    "params = cfg.trpo\n",
    "\n",
    "state_dim = env_one.observation_space.shape[0]\n",
    "action_dim = env_one.action_space.shape[0]\n",
    "hidden_dim = params[\"hidden_dim\"]\n",
    "\n",
    "pi = Actor(state_dim, hidden_dim, action_dim)\n",
    "beta = Actor(state_dim, hidden_dim, action_dim)\n",
    "critic = torch.nn.Sequential(\n",
    "                torch.nn.Linear(state_dim, hidden_dim),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(hidden_dim, 1))\n",
    "agent = trpo_peb.TRPO(pi, beta, critic, params[\"network_settings\"])\n",
    "crit_opt = torch.optim.Adam(critic.parameters())\n",
    "ep, rew, agent = train_standard(env_one, agent, crit_opt, batch_size=4096, iterations=500, log_interval=10, render=False, fname=\"main_0.1_rad\")\n",
    "agents, episodes, rewards = [], [], []\n",
    "agents.append(agent)\n",
    "episodes.append(ep)\n",
    "rewards.append(rew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from types import MethodType\n",
    "\n",
    "env_two = TrajectoryEnvCompare()\n",
    "env_two.goal_thresh = 0.1\n",
    "env_two.reward = MethodType(reward_func, env_one)\n",
    "\n",
    "params = cfg.trpo\n",
    "\n",
    "state_dim = env_two.observation_space.shape[0]\n",
    "action_dim = env_two.action_space.shape[0]\n",
    "hidden_dim = params[\"hidden_dim\"]\n",
    "\n",
    "pi = Actor(state_dim, hidden_dim, action_dim)\n",
    "beta = Actor(state_dim, hidden_dim, action_dim)\n",
    "critic = torch.nn.Sequential(\n",
    "                torch.nn.Linear(state_dim, hidden_dim),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(hidden_dim, hidden_dim),\n",
    "                torch.nn.Tanh(),\n",
    "                torch.nn.Linear(hidden_dim, 1))\n",
    "agent = trpo_peb.TRPO(pi, beta, critic, params[\"network_settings\"])\n",
    "crit_opt = torch.optim.Adam(critic.parameters())\n",
    "ep, rew, agent = train_standard(env_one, agent, crit_opt, batch_size=4096, iterations=500, log_interval=10, render=False, fname=\"main_0.1_rad\")\n",
    "agents, episodes, rewards = [], [], []\n",
    "agents.append(agent)\n",
    "episodes.append(ep)\n",
    "rewards.append(rew)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:python3.5]",
   "language": "python",
   "name": "conda-env-python3.5-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
